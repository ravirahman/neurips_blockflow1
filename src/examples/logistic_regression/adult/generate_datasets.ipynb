{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "from typing import Union\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(\"../../../\")\n",
    "\n",
    "from examples.logistic_regression.adult.dataset import adult_csv_to_dataframe, adult_df_to_dataset\n",
    "from examples.logistic_regression.model import LogisticRegressionTrainingModel, LogisticRegressionTrainingModelParams, LogisticRegressionEvaluationModelParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fake:  # wrapper to denote to generate data that is representative but not necessarily correct\n",
    "    def __init__(self, fraction, *, attack_type: str):\n",
    "        self.fraction = fraction\n",
    "        self.attack_type = attack_type\n",
    "\n",
    "def generate_rel_split(num_special_agents: int, num_normal_agents: int, special_agent_factor: float):\n",
    "    denom = num_special_agents * special_agent_factor + num_normal_agents\n",
    "    answer = []\n",
    "    for _ in range(num_special_agents):\n",
    "        answer.append(special_agent_factor/denom)\n",
    "    for _ in range(num_normal_agents):\n",
    "        answer.append(1/denom)\n",
    "    return answer\n",
    "    \n",
    "\n",
    "# dict of names to split sequences.\n",
    "# each subsequence is a sequence of tuples representing what % of the (false data, true data) each client should have. True data and false data %s must each sum to 1.0\n",
    "SPLITS = {\n",
    "    # symmetric and equal splits\n",
    "    \"sym_eq_1\": (1.0,),  # one client with everything\n",
    "    \"sym_eq_3\": [1/3] * 3,  # 3 clients with equal splits\n",
    "    \"sym_eq_3\": [1/5] * 5,  # 3 clients with equal splits\n",
    "    \"sym_eq_25\": [1/25] * 25,  # 25 clients with equal splits\n",
    "    \"sym_eq_50\": [1/50] * 50,  # 50 clients with equal splits\n",
    "    \"sym_eq_100\": [1/100] * 100,  # 50 clients with equal splits\n",
    "\n",
    "    # symmetric but unequal splits\n",
    "    \"sym_neq_50x0.125\": generate_rel_split(10, 40, .125),\n",
    "    \"sym_neq_50x0.25\": generate_rel_split(10, 40, .25),\n",
    "    \"sym_neq_50x0.5\": generate_rel_split(10, 40, .5),\n",
    "    \"sym_neq_50x0.75\": generate_rel_split(10, 40, .75),\n",
    "    \"sym_neq_50x1.5\": generate_rel_split(10, 40, 1.5),\n",
    "    \"sym_neq_50x2\": generate_rel_split(10, 40, 2),\n",
    "    \"sym_neq_50x4\": generate_rel_split(10, 40, 4),\n",
    "\n",
    "\n",
    "    # attack splits\n",
    "    \"attack_random_50_one\":       [1/50] * 49 + [Fake(1/50, attack_type='random')],\n",
    "    \"attack_random_50_quarter\":   [1/50] * 38 + [Fake(1/50, attack_type='random')] * 12,\n",
    "    \"attack_random_50_half\":      [1/50] * 26 + [Fake(1/50, attack_type='random')] * 24,\n",
    "    \"attack_inverted_50_one\":     [1/50] * 49 + [Fake(1/50, attack_type='inverted')],\n",
    "    \"attack_inverted_50_quarter\": [1/50] * 38 + [Fake(1/50, attack_type='inverted')] * 12,\n",
    "    \"attack_inverted_50_half\":    [1/50] * 26 + [Fake(1/50, attack_type='inverted')] * 24,\n",
    "}\n",
    "VALIDATION_FRACTIONS = [0.2]  # put aside 20% of the records for validation. Not gonna sweep on this\n",
    "DATA_FOLDER = \"/path/to/data/root/folder/adult\"\n",
    "os.makedirs(DATA_FOLDER, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = adult_csv_to_dataframe(\"adult.data\")\n",
    "df_test = adult_csv_to_dataframe(\"adult.test\")\n",
    "adult_df_to_dataset(df).save(os.path.join(DATA_FOLDER, \"train_validate.dat\"))\n",
    "adult_df_to_dataset(df_test).save(os.path.join(DATA_FOLDER, \"test.dat\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shuffle = df.sample(frac=1)\n",
    "df_shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shuffle.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_df(df: pd.DataFrame, start_i: int, fraction: Union[float, Fake]):\n",
    "    if isinstance(fraction, float):\n",
    "        num_records = int(fraction * len(df))\n",
    "        new_df = df.iloc[start_i:start_i+num_records]\n",
    "        new_start_i = start_i + num_records\n",
    "        return (new_start_i, new_df)\n",
    "    else:\n",
    "        assert isinstance(fraction, Fake)\n",
    "        num_records = int(fraction.fraction * len(df))\n",
    "        real_df = df.iloc[start_i:start_i+num_records]\n",
    "        if fraction.attack_type == \"random\":\n",
    "            fake_data = real_df.to_numpy(copy=True)\n",
    "            for i, column in enumerate(real_df.columns):\n",
    "                size = len(real_df)\n",
    "                if real_df.dtypes[column] == int or real_df.dtypes[column] == float:\n",
    "                    mean = real_df[column].mean()\n",
    "                    std = real_df[column].std()\n",
    "                    fake_data[:, i] = np.random.normal(mean, std, size=size)\n",
    "                else:\n",
    "                    names = []\n",
    "                    counts = []\n",
    "                    for name, count in real_df[column].value_counts().items():\n",
    "                        names.append(name)\n",
    "                        counts.append(count)\n",
    "                    np_counts = np.array(counts, dtype=np.float)\n",
    "                    np_counts /= np.sum(np_counts)\n",
    "                    fake_data[:, i] = np.random.choice(names, size=size, replace=True, p=np_counts)\n",
    "            fake_df = pd.DataFrame(data=fake_data, columns=real_df.columns).infer_objects()\n",
    "        else:\n",
    "            assert fraction.attack_type == \"inverted\"\n",
    "            fake_df = real_df.copy(deep=True)\n",
    "            fake_df.loc[fake_df['income'] == '<=50K', 'income'] = 'FAKE'\n",
    "            fake_df.loc[fake_df['income'] == '>50K', 'income'] = '<=50K' \n",
    "            fake_df.loc[fake_df['income'] == 'FAKE', 'income'] = '>50K'\n",
    "        new_start_i = start_i + num_records\n",
    "        return (new_start_i, fake_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for split_name, split in SPLITS.items():\n",
    "    i = 0\n",
    "    for validation_size in VALIDATION_FRACTIONS:\n",
    "        split_folder = os.path.join(DATA_FOLDER, f\"split_{split_name}_validation_fraction_{validation_size}\")\n",
    "        shutil.rmtree(split_folder, ignore_errors=True)\n",
    "    for client_i, fraction in enumerate(split):\n",
    "        assert i < len(df_shuffle)\n",
    "        i, new_df = slice_df(df_shuffle, i, fraction)\n",
    "        for validation_size in VALIDATION_FRACTIONS:\n",
    "            train_size = int((1 - validation_size) * len(new_df))\n",
    "            train_df = new_df[:train_size]\n",
    "            validation_df = new_df[train_size:]\n",
    "            split_folder = os.path.join(DATA_FOLDER, f\"split_{split_name}_validation_fraction_{validation_size}\")\n",
    "            client_folder = os.path.join(split_folder, f\"client_{client_i}\")\n",
    "            os.makedirs(client_folder)\n",
    "            print(\"Saving to \", client_folder)\n",
    "            adult_df_to_dataset(train_df).save(os.path.join(client_folder, f\"train.dat\"))\n",
    "            adult_df_to_dataset(validation_df).save(os.path.join(client_folder, f\"validation.dat\"))\n",
    "            adult_df_to_dataset(new_df).save(os.path.join(client_folder, \"score.dat\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}